---
date created: 2022-10-12 17:59
---

## 流程

- 前台
  - 计算文件总体hash 值（可以使用 webworker），
  - 发送请求 A： 传递hash值 判断是否存在相同文件，存在 秒传；
  - 生成文件切片 （ Blob.prototype.slice() ）
  - 每个文件添加哈希值 ：文件名 -hasha -chunkIndex
  - 并发请求 B 将切片传输给服务端 （单文件上传进度可以使用 axios 的 onUploadProgress）
  - 发送文件合并请求 C 进行文件合并
- 后台
  - 接受请求A； 查询数据库有无相同hash的文件 有复用，没有创建文件记录等待文件上传。
  -
  - 接受切片，暂时存储在一个位置
  - 接受合并请求C， 暂存位置合并文件计算整体hash 与前端结算的hash 对比 相同 结束上传。
  - 合并完后删除分片。

## 具体流程

### 前台切片

```js
  

const container = { file: null }

// 选择文件改变后 更新到容器汇总
const handleFileChange = (e) => {

const [file] = e.target.files;

if (!file) return;

container.file = file;

};

  

/**

* 生成文件切片

* @param file 文件

* @param size chunk大小

*/

function creatFileChunk(file:File, size:number) {

// 切片结果

const fileChunkList = [];

let cur = 0;

while (cur < file.size) { // 字节数

fileChunkList.push({ file: file.slice(cur, cur + size) });

cur += size;

}

return fileChunkList;

}

// 并发上传

const uploadChunk = async (data:any[]) => {

const requestList = data.map(({ chunk, hash }) => {

const formData = new FormData();

formData.append('chunk', chunk);

formData.append('hash', hash);

formData.append('filename', (container.file as File).name);

  

return formData;

}).map((formaData:FormData) => {

asyncChunkUpload(formaData);

});

await Promise.all(requestList);

};

// 按钮--分片上传

const handleUpload = async ():Promise<void> => {

if (!container.file) return;// 容器没有文件直接放回

const size = 10 * 1024 * 1024;

const fileChunk = creatFileChunk(container.file as File, size);

const data = fileChunk.map(({ file }, idx) => ({ chunk: file, hash: `${(container.file as File).name}-${idx}` }));

  

await uploadChunk(data);

};
```

### webworker 计算hash

> webworker 无法直接在线程中操作 Dom 元素，一些 window 对象的某些方法也无法调用。

不过可以使用
引用第三库 ，路径webpack 会解析成绝对路径

```js
//	worker.js
self.importScripts('./filters.js')


//============= OR  =====================

new Worker('worker.js',{type:'module'})

// ===== workerjs 
import * as filters from "./filters.js";

```

### 合并切片

```js
const http = require("http");

const path = require("path");

const fse = require("fs-extra");

const UPLOAD_DIR = '/xxx/xxx/xx';

// const UPLOAD_DIR = path.resolve(__dirname, "..", "target");

  

//写入文件流

const pipeStream=(path,writeStream)=>{

new Promise(resolve=>{

const readStream= fse.createReadStream(path);

  

readStream.on('end',()=>{

fse.unlinkSync(path);// 读去完 删除

resolve()

})

readStream.pipe(writeStream)

})

}

/**

* 合并请求调用 方法 合并切片

* @param {*} filePath 合并后文件地址

* @param {*} filename 文件名

* @param {*} size 文件chunk 大小

*/

const mergeFileChunk = async (filePath, filename, size) => {

const chunkDir = path.resolve(UPLOAD_DIR, `chunDir${filename}`);

const chunkPaths = await fse.readdir(chunkDir); // 获取全部文件路径；

  

// 对全部chunk 路径名进行排序 升序

chunkPaths.sort((a, b) => a.spilt('-')[1] - b.spilt('-')[1]);

  

// 将全部chunk 合并

  

await Promise.all(

chunkPaths.map((chunkPath,index)=>{

pipeStream(

path.resolve(chunkDir,chunkPath), //目录 + chunk 名参数

fse.createWriteStream(filePath,{

start:index*size, // 写入指定位置。

})

)

})

)

// 合并完后删除 保存切片的目录

fse.rmdirSync(chunkDir)

};

```
